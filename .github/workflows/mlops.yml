name: Titanic MLOps Pipeline

on: [push, pull_request]

jobs:
  data-processing:
    name: Data Processing with DVC
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Setup DVC
        run: |
          python -m dvc init --no-scm -f
          mkdir -p dvc_remote
          python -m dvc remote add -d localremote dvc_remote/

      - name: Get DVC data
        run: |
          # For CI, we download data since no cloud remote is configured
          # In production, replace with: python -m dvc pull
          echo "Downloading data for CI environment"
          mkdir -p data/raw
          curl -L "https://raw.githubusercontent.com/dsindy/kaggle-titanic/master/data/train.csv" -o data/raw/train.csv
          curl -L "https://raw.githubusercontent.com/dsindy/kaggle-titanic/master/data/test.csv" -o data/raw/test.csv
          curl -L "https://raw.githubusercontent.com/dsindy/kaggle-titanic/master/data/gender_submission.csv" -o data/raw/gender_submission.csv

      - name: Run DVC Pipeline
        run: |
          python -m dvc repro

      - name: Upload processed data
        uses: actions/upload-artifact@v4
        with:
          name: processed-data
          path: |
            data/interim/
            data/processed/

  model-training:
    name: Train ML Models
    runs-on: ubuntu-latest
    needs: data-processing
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Download processed data
        uses: actions/download-artifact@v4
        with:
          name: processed-data
          path: data/

      - name: Train ML Models
        run: |
          python src/train.py

      - name: Upload MLflow artifacts
        uses: actions/upload-artifact@v4
        with:
          name: mlflow-runs
          path: |
            mlruns/
            mlflow.db

  model-registration:
    name: Register Best Model
    runs-on: ubuntu-latest
    needs: model-training
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Download MLflow artifacts
        uses: actions/download-artifact@v4
        with:
          name: mlflow-runs

      - name: Register Best Model
        run: |
          python src/register_model.py

      - name: Display Metrics
        run: |
          echo "Pipeline successful."
          echo "Recent MLflow runs:"
          python -m mlflow experiments search
          python -m mlflow runs list --experiment-id 1 || true
          echo "MLflow logs created."

  data-monitoring:
    name: Data Drift Monitoring
    runs-on: ubuntu-latest
    needs: model-registration
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Run Monitoring
        run: |
          # Ensure directories exist
          mkdir -p data/raw
          # Simulating data download since DVC remote isn't accessible in CI
          curl -L "https://raw.githubusercontent.com/dsindy/kaggle-titanic/master/data/train.csv" -o data/raw/train.csv
          curl -L "https://raw.githubusercontent.com/dsindy/kaggle-titanic/master/data/test.csv" -o data/prod.csv
          python src/monitoring.py

      - name: Upload Monitoring Reports
        uses: actions/upload-artifact@v4
        with:
          name: drift-reports
          path: |
            data/monitoring/
            train_stats.json
