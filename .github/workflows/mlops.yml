name: Titanic MLOps Pipeline

on: [push, pull_request]

jobs:
  run-pipeline:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Setup DVC
        run: |
          python -m dvc init --no-scm -f
          mkdir -p dvc_remote
          python -m dvc remote add -d localremote dvc_remote/

      - name: Get DVC data
        run: |
          # For CI, we download data since no cloud remote is configured
          # In production, replace with: python -m dvc pull
          echo "Downloading data for CI environment"
          mkdir -p data/raw
          curl -L "https://raw.githubusercontent.com/dsindy/kaggle-titanic/master/data/train.csv" -o data/raw/train.csv
          curl -L "https://raw.githubusercontent.com/dsindy/kaggle-titanic/master/data/test.csv" -o data/raw/test.csv
          curl -L "https://raw.githubusercontent.com/dsindy/kaggle-titanic/master/data/gender_submission.csv" -o data/raw/gender_submission.csv

      - name: Run DVC Pipeline
        run: |
          python -m dvc repro

      - name: Display Metrics
        run: |
          echo "Pipeline successful."
          echo "Recent MLflow runs:"
          python -m mlflow experiments search
          # Listing runs by ID (ID 1 is typically our Titanic experiment)
          python -m mlflow runs list --experiment-id 1 || true

      - name: Log results to MLflow
        run: |
          echo "MLflow logs created."
